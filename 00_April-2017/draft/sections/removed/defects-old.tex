\providecommand{\main}{..}					% fix bibliography path
\documentclass[\main/IO-Pixels.tex]{subfiles}
   
\graphicspath{{\main/fig/exploratory/}}			% fix graphics path
%======================================================================

\begin{document}

\section{Identification of defects}

\CB{Have split this out as a separate section for now, mainly to keep the working files to a manageable size}

The approach to defect finding used by the manufacturer relies on identification of extreme values in offset-corrected images ($W-B, G-B$), and sometimes also gain-corrected images. In defining an official dead pixel map, precise classification of pixel behaviour is not necessary;  a pixel either does or does not need further correction, and so either should or should not be included in the bad pixel map. For a more detailed investigation of the progression of pixel defects, a more subtle classification is required. The manufacturer's software relies on identification of abnormal values in offset-corrected images ($W-B, G-B$), but in order to more fully track and describe the development of defects, we also search for abnormal values in the uncorrected pixelwise mean images. This broader approach allows for the identification of defects not yet severe enough to persist into a shading-corrected image, but which may in time develop into a more severe defect.

The approach as given in the manual can be a little vague; a `no gain' pixel is simply defined as `dark pixel with no light response', but no indication is given of how this should be classified. In practice, a pixel with no gain response will return very similar values in the black, grey and white images; depening on the spread of the remainder of the image, these will almost all fall below the threshold for an underperforming dark pixel.  

\addfigure{Note that we want to track development of pixels, \& to identify any abnormal behaviour, even if only in one image. So use black/grey/white median-differencing to identify local defects; do we still need extreme-value identification? Can be unreliable if data is more spread than expected, but this defect is more to do with a problem across the detector than with individual pixels (eg. in doughnut-shaped image). Also separate identification of screen spots; this should be done every time, to avoid misclassification, because this issue only occurs in grey \& white images: no corresponding offset in black images. Identify pixel defects using each method (`official', SC median-diff (`gold standard'), bgw median-diff, extreme-value); initially simply classify as defective, but can later split into degrees of defect depending on values.}


\subsection{Abnormal pixels}

The most appropriate approach to identifying defective pixels will vary depending on the user's intention. If the aim is to generate a map of those pixels that will remain problematic after shading correction, we can simply generate a smooth shading-corrected image by using Equation~\ref{eq:shading-correction} with the pixelwise grey mean image $G$ substituted in place of $X$, and look for deviations from normal behaviour there (Section~\ref{sec:sc-defects}). Furthermore, different levels of stringency may be necessary depending on the intended use of the image - for example, static imaging is more tolerant of defective pixels than CT reconstruction, as outlined in \ref{app:tab:n-bad-px}.  Our aim in this study is to capture as many abnormal pixels as possible, in order to investigate any changes in pixel behaviour over time, so we first describe an approach that will not only identify defects, but will also allow classification according to their type and severity.

\subsubsection{Defects in any image}
In order to obtain a detailed classification of pixel defects, we must work with the raw pixelwise mean images, rather than offset-corrected versions; for example, if we consider a grey offset-corrected image $G-B$, we are considering only the difference between the black and grey images, so it is impossible to distinguish between a pixel that has low values in both images, and one that has high values in both images: both will show as a low value in the offset-adjusted image, but we have lost the information regarding the type of defect that has occurred. In order to retain more detail for classification, we consider abnormalities at each power setting separately.

Generally, the most obvious defects are \textbf{dark pixels}, which do not exhibit any change in response when the x-ray source is switched on. These are usually clearly visible in illuminated images, where they appear black or dark, but often behave normally in the black images. Dark pixels can easily be identified by direct thresholding of a bright image; generally the white image is to be preferred over the grey, because of the greater separation between the typical white value and the typical black value, allowing a clearer distinction between normal and dark pixels. In all 21 acquisitions in the study data set, 99.99\% of all observed black pixels had a value of less than 9940, suggesting that this is a sensible threshold below which a single pixel in any illuminated image should be classified as dark. In practice, a slightly higher threshold of 15000GV was applied; this is to ensure that any columns of dark pixels, which sometimes increase in value toward the readout sensor as readout charge accumulated (Section~\ref{sec:column-defects}, are captured in their entirety, while still remaining well below the normal dynamic range of the white images.


Once these obvious defects are captured, the most direct means of identifying pixels that behave abnormally is to identify those pixels whose values differ significantly from their neighbours. To identify pixels with an abnormal background current, we will use a dark image, and to identify any pixels with an abnormal response, we use an illuminated image. Pixel response will differ in degree between the grey and white images, but not usually in type, so to avoid unnecessary duplication of work we will use only the dark image $B$ and the illuminated grey image $G$, which has a lower variance than the white image.

For each of these pixelwise mean images, we obtain a median-smoothed image by convolution of the image with a filtering kernel, replacing the value of each pixel $i$ with the median of the values in a $7 \times 7$ square centred at $i$. A kernel of any size or shape could, in theory, be used; a 7-square kernel will smooth out any defects spanning up to 3 columns, square defects of $4 \times 4$ pixels, and circular defects of diameter 5 pixels. Larger defects can occur, but with the exception of dim spots caused by contamination of the detector window (Section~\ref{sec:screen-spots}), none were seen \nb{double-check} within the study data. Larger defects are only expected to occur in detectors in which there is heavy damage \nb{should phrase better}, and will be likely be large enough to be spotted by the operator; in this case, a larger kernel can be used accordingly, but should always have an odd number of pixels on each side so that it can be centred on $i$.

The smoothed image is subtracted from the original mean image to give a detrended residual image, retaining only each pixel's distance above or below its approximate expected value. This flattened image can easily be thresholded to identify any unusually dim or bright pixels. Using the median-smoothed image to obtain the residuals, rather than any parametric model or taking differences between rows or columns, reduces the risk of falsely identifying as abnormal pixels along the edges of subpanels, where abrupt changes in value are common. In addition, where pixel $i$ is a dark pixel, its residual value is replaced with 0; dark pixels frequently appear in long columns, the presence of which can have a large effect on the variance of the overall pixel population, leading to wider-than-appropriate pixel thresholds.

Rather than simply thresholding the values at the median value $\pm 6 \cdot \sigma$, we find sensible cutpoints using the Johnson Distribution \nb{cite \& give brief description of parameters \& fitting}. After fitting a Johnson distribution to the residuals, we calculate the quantiles of the fitted distribution that will give us the desired probability range, and cut the data accordingly. Depending on the length and weight of the tails of the distribution, the cutpoints can be adjusted, but a sensible starting level (and the one applied to obtain the pixel maps used in later sections) is to find the quantiles of the Johnson distribution that correspond to $5\sigma$ probabilities: \nb{translate: \texttt{qJohnson(pnorm(c(-5,5), 0, 1), JF)} where \texttt{JF <- JohnsonFit(md7[,,"black", ][!is.na(md7[,,"black", ])])}}. Use of the more flexible Johnson distribution, rather than simply cutting at $\pm 5\sigma$, takes some account of the skewness in the residuals. The fit of the Johnson distribution can be checked graphically by producing a Q-Q plot; with such a large data set, goodness-of-fit tests are of little practical use, rejecting the null hypothesis unless the fit is extremely close to perfect; since we are using the quantiles of the distribution precisely to identify outliers, such a test is almost guaranteed to fail unless there are no outliers to find. However, the distribution is generally very well fitted in the central range \nb{figs if space - maybe in appendix?}, making it serviceable for our purposes.

To obtain ordinal categories of pixel abnormalities in order to study the development of defects in more detail, we apply further thresholds to the data. Table \nb{ref} shows the pixel categories identified in each of the 21 acquisitions that form the main data set.

\addfigure{table of categories. High number of locally bright pixels observed in `main sequence' panel: check whether in grey or black images (eg. does offset persist at all power settings?). How does pixelwise SD in those images compare to that of others?}


\todo{nonlinear response: linear regression of white/grey images, identify extreme residuals. Are nonlinear pixels usually found in conjunction with others or singly? How does the pattern from offset defects? Expect that nonlinearity is pixel-specific and therefore independent of neighbours, while offset defects are more likely to appear in  clusters (supporting theory that this is a charge leakage with a single root cause, rather than a cluster of independently-defective pixels)}



\subsubsection{Defects in shading-corrected image}
\label{sec:sc-defects}

\nb{are any pixels picked up in SC image but not in any of the others?}

Need to consider \& justify the local thresholding limit. Currently using 2x SD of image as limit for median differences, but would surely make more sense to use a pixelwise standard deviation? Or even a local standard deviation (eg. standard deviation within kernel region)

\addfigure{Histograms showing thresholds of extreme-valued pixels}
\addfigure{Linear regression of white vs black \& grey images, showing thresholding by residuals}

\addfigure{Comparison of `official' classifications given in manual vs our thresholds}

\subsection{Defects affecting multiple pixels}

%===================================================================================================================================================

\subsubsection{Column defects}

\label{sec:column-defects}

\nb{function is picking up too many false positives in some images based on short segments after thresholding - need to rework after changepoint classification (perhaps use CP as root, then return to original values to identify which segments should actually be included?)}

\addfigure{Linear defects detected by subtracting a median-filtered image from the original, then convolution \& thresholding over the residuals. Since linear defects may be 2 or 3 pixels wide (4 pixels is possible, according to the manual, but not yet observed), the smoothing kernel should be at least 7 pixels wide (5 pixels and a 3-pixel line cannot be smoothed out, 3 pixels wide and a 2-pixel line cannot be smoothed out) \nb{Actually, with a square kernel (as in edge detection in traditional image processing), we lose detail where there are multiple adjacent columns. Could try linear kernel, or omit linear convolution step altogether?}}

\addfigure{Most obvious linear defects are dark pixels, which can be identified by simple thresholding \& clumping. Replace these with med-smoothed values, then run convolution over residuals. Haven't observed thicker columns of bright/hot pixels, and dark pixels tend to be brightest column, so this reduces to a maximum thickness of 1-2px either side of dark column, which we should be able to find by convolution (look at triple column in MCT225 to check that this works: may need split kernel/double-line kernel?)}

Data in a CCD panel is read out by transferring charge vertically along columns, \nb{CONFIRM} from the midline towards amplifiers situated at the outer edges of the panel (or, in the case of the AN1620 model used to capture acquisition MCT225 - which has no midline - from the bottom to the top of the panel). It is not uncommon for a single defective pixel (or cluster of pixels) to affect the behaviour of other pixels in the same column. In the most severe cases, the defect forms a blockage and a column of dark pixels will occur (\autoref{fig:dark column}), the result of a failure to transfer the charge from `upstream' pixels past the defect. In less severe cases, a defect may `drain' charge - resulting in a slight decrease in the values of the upstream pixels - or `leak' charge, resulting in a slight increase in the values of the downstream pixels. In these cases, the amount of offset from the neighbouring columns generally remains constant along the affected segment at all power settings \nb{check this: need to enumerate all types of column identified \& behaviour in each}. A procedure for identifying column defects is outlined in \nb{ref}.

\nb{Have led with assumed cause - could rearrange this to start with only observed features (bright/dim/dark lines), then move on to explaining that likely reason is to do with charge being blocked, drained or leaked: all electronic faults that cause equal offset at all power settings. Gain response is unique to each pixel, so to see a row of abnormal gain responses would be quite surprising}

Close inspection of transects along dark columns in the grey and white images sometimes shows that a stepped or sawtooth pattern of values, increasing at regular intervals  \nb{try to include this in the example images}. This regularity suggests that no additional charge is being added from the pixels along the dark column, that the root defect is somehow blocking its transfer along the channel to the readout sensor \nb{ideally, could relate this gradient to y-gradient along subpanel, but this is a tall ask}.

%----------------------------------------------------
% transects along each type of column defect
\begin{figure}[!ht]
\caption{Pixel images and column transects showing known types of column defect in the dark images acquired on 13-11-22. In each transect, the defective column is shown in black, with an unaffected neighbouring column shown in blue for reference.}

	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Dark pixels (column )}
	\label{fig:dark column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Bright pixels}
	\label{fig:bright column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Slightly dim pixels}
	\label{fig:dim column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Bright and dim pixels}
	\label{fig:bright-dim column}
	\end{subfigure}
	
\end{figure}
%----------------------------------------------------	

\addfigure{Mention decreased variability along dark lines (and sometimes bright or dim?}

%----------------------------------------------------
% procedure to identify column defects
\begin{algorithm}
    \caption{Procedure for identifying column defects (Row defects can be identified in the same way by using the transpose of each image array as inputs)}
	\label{proc:lines}

    \SetKwInOut{Input}{Input}
    \SetKwInOut{Parameters}{Parameters}

    \Input{Bright image without offset correction $W$; residuals $\Delta_B$ after median-smoothing of dark image $B$}
    \Parameters{Threshold for dark pixels $\theta_D$, \\Edge detection kernel size $k$, \\Threshold for linear feature $\lambda$, \\ Minimum segment length $l$}

Identify dark pixels $\{ i: W(i) < \theta_D \}$ and select those that form vertical linear clusters

Remove any extreme-valued pixels: set $\{ \Delta_B (i) : |\Delta_B(i)| > 3000 \} = 0$ to obtain adjusted residuals $\tilde{\Delta}_B$ \nb{what is a sensible limit to use for `extreme' pixels for removal here?}

Convolve $\tilde{\Delta}_B$ with edge-detection kernel of size $k$

Threshold image at $\pm \lambda$ to identify lines of bright or dim pixels

Identify vertical clusters in thresholded image and discard any of length $\le l$

Apply changepoint detection algorithm to identify most likely break in line values

if no breakpoint, assume whole column is offset and ignore (unless above a certain threshold?)

Classify line segments as bright or dim according to their mean value

For pixels $i$ on line segments classified as bright or dim, set $\Delta_G(i)$ = 0

Repeat convolution, thresholding, clustering and changepoint identification in adjusted residuals $\tilde{\Delta_G}$

\end{algorithm}
%----------------------------------------------------

\nb{when searching for row defects, rather than column defects, it is advisable to use a higher \texttt{min.length} parameter. This is because bright pixels appear to be more likely to spread horizontally than vertically (?!), so are likely to be smeared into longer line segments. A threshold of 15px rather than 10 is usually sufficient (need to add in an analysis of how long a feature will be ignored/included by this, and relate to analysis of what we actually observe. Maybe a plot of cluster height vs cluster width (\& total brightness as colour/size) to show the main relationship, using the latest image set from each sequence}

\subsubsection{Cluster defects}
Abnormal pixels may appear scattered singly across the detector, but frequently also appear in clusters of adjacent pixels. Such clusters do not appear to arise from a collection of individually-occuring pixels; rather, the pixels all form part of a single defect, often with brighter (or sometimes completely dark) pixels in the centre, and less-bright pixels at the edges \nb{give examples of typical clusters: hot, dead, round, horizontal, with line} After a list of coordinates of abnormal pixels is created, adjacent individuals can easily be grouped using the \texttt{clump} 

\addfigure{May be result of single physical damage/cosmic ray affecting several pixels (known cause of hot pixels? Check Hubble documentation), or of a single pixel that affects others (bleeding/blooming - especially with `overflowing' pixel)}

\addfigure{How often do clusters appear in conjunction with lines? And vice versa? Is there a `typical' makeup of a line-root cluster? Also, enumerate number of clusters with horizontal spread - with only vertical spread (excl. line roots) - with spread in both directions.}



\subsection{Assessing general detector health: deviations from circular spot}

\nb{Probably shouldn't introduce this first, since not an appropriate way to classify individual bad pixels (since bad model fitting could cause high residuals). Maybe could include this after general thresholding approach, and just add regional damage into bad pixels already classified?}
% essentially: find defects using the same thresholding approach, but over different images. General problems with panel response are found as deviations from a circular spot, while pixel deviations are better identified as deviations from local (median-smoothed) image. Still need to decide best order in which to carry out these two classifications.

The grey and white images are obtained by exposing the detector to an x-ray source with nothing in the field of view. X-rays diffuse out from the source in a conical shape until they strike the detector; a hypothetical `perfect' detector, \nb{get citation - speak to Jay} then, would register a circular spot pattern in the white and grey offset images (that is, white and grey images from which the black image has been subtracted, leaving only the detector's response to the presence of x-rays), and the response $z_i$ at each pixel $(x_i, y_i)$ would be well modelled by a two-dimensional Gaussian distribution, centred at the focal point $(x_0, y_0)$ of the x-ray beam and with variances $\sigma_x$ and $\sigma_y$ reflecting the degree of dispersion of the x-rays:

\[ z_i = \frac{1}{2\pi \sigma_X \sigma_Y \sqrt{(1-\rho^2)}} \exp \left[ -\frac{1}{2(1-\rho^2)} \left[ \left(\frac{x_i-xy_0}{\sigma_X}\right)^2 + \left(\frac{y_i-y_0}{\sigma_Y}\right)^2 - 2\rho\left(\frac{x_i-x_0}{\sigma_X} \right) \left(\frac{y_i-y_0}{\sigma_Y} \right) \right] \right] \]

To simplify the model, we assume that the x-ray source is directed at the centre of the panel in both axes, and that the source is more or less orthogonal to the panel, so that there is minimal stretching or distortion of the spot. We therefore fix $\rho = 0$ - since non-zero covariance would lead to a diagonal stretching of the spot - and constrain $x_0$ and $y_0$ to fall within a square with its centre at the exact midpoint of the panel. The latter constraint may be relaxed where there is good reason to believe that the spot really is off-centre (as in Figure~\ref{fig:spot-constraints-wonky}), and is generally only required when there is a region of non-responsive pixels in the centre of the panel, leading to a response surface with a dip in the centre, as in Figure~\ref{fig:spot-constraints-doughnut}. When this occurs, an unconstrained model will very often centre the spot in the region with the highest output; however, our aim here is to model the most likely location of the spot, not simply to describe the shape of the surface, and since we know that the operator will target the spot in the centre of the panel, it is more useful to force the spot to the most appropriate area.

\nb{Of course, need to check with Jay if this really is the case}

We therefore model the expected response $z$ at each pixel $i$ as

\[ z_i = A \exp \left(-\frac{1}{2} \left\lbrace \left(\frac{x_i - x_0}{\sigma_X}\right)^2 + \left(\frac{y_i - y_0}{\sigma_Y}\right)^2 \right\rbrace \right) , x_0, y_0 \in (768, 1280) \]

%----------------------------------------------------
\begin{figure}[!ht]
\caption{Gaussian spot models fitted to the uncorrected grey images, both with (solid line, square) and without (dashed line, triangle) constraints on the possible values of $x_0$ and $y_0$. \\
\footnotesize{In (a), the spot is centred well within the constrained area, as we might expect, and the same model is fitted with and without the constraint; typical of a healthy panel with a centred spot. However, in (b) and (c), the constrained model has its centre at one of the constraining boundaries. When this occurs, we must decide whether to allow the spot's centre to be placed outside of the constraining area. In (b), the data is unimodal, and well fitted by a model in which the spot is allowed to move outside of the usual area, which gives a significant improvement in RMSE. However, in (c), removing this constraint does not lead to any appreciable improvement in the model, so we conclude that the problem with the fit is not simply one of an off-centre spot, and keep the constraint in place.}}
\label{fig:spot-constraints}

\begin{subfigure}[t]{0.328\textwidth}
\caption{16.04.30: same model fitted with and without constraint: spot well centred.\\RMSE: 186}
\label{fig:spot-constraints-healthy}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-160430}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{16.07.05: RMSE much improved by removing constraint: spot poorly centred \\RMSE: 501 constrained, 226 free}
\label{fig:spot-constraints-wonky}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-160705}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{MCT225: unconstrained model located far from centre, RMSE not much improved by removing constraint: abnormal panel response \\RMSE: 574 constrained, 553 free}
\label{fig:spot-constraints-doughnut}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-MCT225}
\end{subfigure}
%

\end{figure}
%----------------------------------------------------

\addfigure{Consider more systematic approach to model selection. Likelihood-based methods such as AIC, BIC require a log-likelihood; how do we obtain that for a surface (rather than a sparsely-observed set of points)?}

The model is fitted by minimising the squared residuals; any deviations from the expected spot shape will indicate pixels with an abnormal response to exposure to an x-ray source. Thresholding the model's residuals identifies those pixels with the most extreme responses, and these problematic individuals can then be grouped according to their formation (clusters or lines of adjacent pixels, and dense regions of non-contiguous abnormal pixels, for example). Setting an appropriate threshold is not an exact science; a cutoff based on some scalar multiple of the RMSE of the residuals for each image would be a tempting option, in that if we could reasonably assume the residuals to be normally distributed, we would expect to be able to select a controlled proportion of the most severely damaged pixels. However, in several panels we expect to find regions with large numbers of high residuals, which will render this assumption untenable. In addition, taking a simple mean/median RMSE across all of the images acquired in the study is not really reasonable, since we have 12 images from a single fairly `healthy' detector, 6 from a known damaged detector, and two others, so simple averaging would be assuming a misleading degree of population-representativeness. Ideally, we want a measure of the variability of the residuals of healthy pixels.

A number of the panels included in this study have very obvious column defects, which will be discussed further in Section~\ref{sec:column-defects}. These column defects comprise relatively large numbers of pixels with an offset-corrected value close to zero, and when they occur, are the most significant contributor to the non-normality of the residuals. Furthermore, they can be very easily and unequivocally identified. Excluding those panels that exhibit this clear sign of damage, we take the mean RMSE of the remaining panels (242) as an approximate measure of the typical variability of less severely-affected pixels. Using a threshold of 5 times the mean RMSE would, if the residuals were normally distributed with this standard deviation, pick up around 1000 defective pixels in a 2048-square panel: a reasonable minimum sample size with which to assess whether the residuals are clustered in a particular area, or scattered across the entire detector surface. In the data collected to date, the 12 images from the WMG post-refurbishment panel contain no dark lines; taking their mean RMSE gives a limit of 1204, beyond which a residual will be considered abnormally large.

The detector manual defines the defect-density of a region of pixels as the proportion of defects in the surrounding $51 \times 51$ square. Any pixel in which more than 10\% of the pixels in the surrounding block are found to be defective is said to lie in a high-defect-density region. We can apply this same definition to identify any regions of particularly high density in the residuals.
\nb{how are edges handled?}

%----------------------------------------------------
\begin{figure}[!ht]
\caption{Plots of residuals with absolute value greater than 1204 from the three fitted spot models fitted above. Regions of high density are shaded red.
\\ \footnotesize{With a properly fitted spot in (b), (a) and (b) are very similar; these are images taken from the same detector, several weeks apart. There is evidence of damage along the left-hand edge of the panel, extending some way along the top border, but the extreme-valued pixels are otherwise scattered throughout the panel. In the Nikon detector labelled MCT225, on the other hand, there is a very large, dense region of abnormal pixels in the centre of the screen, and several dark lines can clearly be seen.}}

\begin{subfigure}[t]{0.328\textwidth}
\caption{16.04.30: healthy panel,\\ centred spot (2611 px)}
\includegraphics[scale=0.3]{spot-residuals-160430}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{16.07.05: non-centred spot fitted without constraint (2737 px)}
\includegraphics[scale=0.3]{spot-residuals-160705}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{MCT225: dim patch in centre of panel (49425 px)}
\includegraphics[scale=0.3]{spot-residuals-MCT225}
\end{subfigure}
%

\end{figure}
%----------------------------------------------------

The positioning of the x-ray spot, and the panel's response to the exposure, are important not only in identifying potentially underperforming regions of the detector. The thresholding approach applied within the detector manual is rather reliant on the assumption that the pixel values are approximately normally distributed, which in turn relies on an assumption that pixels across the panel respond in a more or less uniform way to a spot focussed at the centre of the panel. 

%----------------------------------------------------
\begin{figure}
    \caption{Histograms of offset-values observed in white images}
    
    \sftriple{white-spot-hist-160430}{16.04.30: centred spot. \\ Lightly skewed}
    %
    \sftriple{white-spot-hist-160705}{16.07.05: off-centre spot. \\ Heavily skewed}
    %
    \sftriple{white-spot-hist-MCT225}{MCT225: dim patch in panel centre. \\ Multi-modal distribution}

\end{figure}
%----------------------------------------------------

As well as the proportion of the screen affected by abnormal pixels, it may also be useful for operators to monitor the mean detector response to a given power setting (or, conversely, the power required to obtain a given mean value), and also the standard deviation of the responses. 

\subsection{External issues: screen spots, defective channels, and edge effects}
%----------------------------------------------------
The main focus of this paper is on defective pixels within the detector panel. However, a number of other issues were observed during the course of the study.
\addfigure{Could also mention the defective subpanel here}

\subsubsection{Spots on the detector window}
\label{sec:screen-spots}

A problem not related to defects in the detector panel itself, but nonetheless one that an operator should be aware of, is the problem of spots appearing on the beryllium window that isolates the x-ray source from the scintillator. These spots occur when the tungsten target is heated by the electron beam to such a degree that flecks of tungsten ping off \nb{find better phrase}, and attach themselves to the beryllium window. Once this occurs, the flecks remain permanently attached to the window until the window is replaced. Figure~\ref{fig:screen-spots} shows the effect of the screen spots in the set of images acquired on 14-10-09.

Screen spots can be particularly problematic for two reasons. Firstly, because they appear only in the presence of an x-ray source and not in the black images, they are not removed by the shading correction (\ref{fig:screen-spots:sc}); and secondly, because their position may appear to shift slightly between separate acquisitions, as the x-ray source is moved and refocused  (\ref{fig:screen-spots:shift}). This means that even if pixels covered by screen spots were added to the bad pixel map for correction, the locations would most likely be invalid for all successive acquisitions. \nb{Is there anything in the image processing to allow screen spots to be corrected, save by switching values?}

%----------------------------------------------------
% screen spots in shading correction & shifting in successive images
\begin{figure}[!ht]
\caption{Screen spots visible in the lower quarter of the white image acquired on 14-10-09 and successive dates (spots are circled for ease of identification)}
\label{fig:screen-spots}

\begin{subfigure}[t]{0.32\textwidth}
\caption{Pixelwise mean white image}
\includegraphics[scale=0.3]{screen-spots/pwm-image-141009-white}
\end{subfigure}
%
\begin{subfigure}[t]{0.32\textwidth}
\caption{White shading-corrected image}
\label{fig:screen-spots:sc}
\includegraphics[scale=0.3]{screen-spots/sc-image-141009-white}
\end{subfigure}
%
\begin{subfigure}[t]{0.32\textwidth}
\caption{Shift in apparent position}
\label{fig:screen-spots:shift}
\includegraphics[scale=0.3]{screen-spots/spots-overplotted}
\end{subfigure}

\end{figure}
%----------------------------------------------------

Screen spots are generally not detected in their entirety by the internal software because of their relatively low intensity difference from their surroundings. However, when looking for small features in a processed image (such as defects in objects produced by additive layer manufacturing), these differences may prove large enough to obscure a defect of a millimetre or two \nb{back up}; so a robust method for identifying such defects is required. Our solution to this problem is outlined in \autoref{proc:screen-spots}.

%----------------------------------------------------
% procedure to identify screen spots
\begin{algorithm}
    \caption{Procedure for identifying spots on beryllium window}
	\label{proc:screen-spots}

    \SetKwInOut{Input}{Input}
    \SetKwInOut{Parameters}{Parameters}

    \Input{Bright image without offset correction $W$}
    \Parameters{Minimum spot diameter, $d$ \\ Lowess smoothing span, $f$ \\ y-coordinate of midline (if any), $\lambda$}

Adjust offset of columns in upper panel (if midline exists)

Detrend each column by subtracting Lowess-smoothed value with span $f$ from offset-adjusted value

Truncate values by setting all pixel values above median value to median value

Apply morphological closing with disc-shaped structuring element, diameter $d$, to truncated image

Threshold resulting image to give binary classification for each pixel

%Filter spots, using 75th quantile of detrended residuals to assess `depth'

Dilate identified spots to approximately reconstruct edges lost in thresholding

\end{algorithm}
%----------------------------------------------------

%If we were to plot the pixel values from a single column of a white image without screen spots, we would expect to observe a smooth curve, with its highest point at the focal point of the x-ray source. Where a spot falls on the  \nb{add figure? Already a lot of figures...}
Our aim is to fit a smooth spline to each column of the image array, to use this spline to de-trend each column's data, and to identify large, round-edged dips in the detrended residuals. Detrending in both directions at once is theoretically possible, but two-dimensional spline fitting is extremely time-consuming, whereas the implementation suggested here can be applied in a matter of minutes \nb{benchmark final process}. We use columns rather than rows to minimise the number of subpanels crossed by each spline, since the response surface is usually discontinuous at boundaries between subpanels. 

Rather than fit a separate spline to the upper and lower segment of each column - which would result in a horizontal strip of unfitted pixels across the critical central region of the panel at the end of each spline - we first apply an offset correction to smooth the join between the upper and lower columns. Since the absolute values are currently of no real interest, for each column we calculate the median value of the 100 pixels above and below the midline, and subtract the difference from the values of the upper column, resulting in a smooth gradient across the midline in each column (Figure \ref{fig:screen-spots:offset}). 

The overall trend of the pixel responses in each column is modelled by fitting a nonparametric Lowess curve to the offset-adjusted values. The function is controlled by a smoothing parameter $\alpha$, denoting the proportion of the available data to be used in fitting each point. This smoothing span must be sufficiently large that the fitted curve does not follow the short dips in value caused by the presence of contaminants on the screen, but small enough that we don't lose too many pixels at the upper and lower edges of the panel. On the data sets available, smoothing spans using anything between 1/5 and 1/35 of the points produced reasonably similar results. The former requires 410 data points to fit each value, so is unable to fit a smoothed curve within 205 pixels of the upper and lower edges of the panel; the latter uses 59 points to fit each value, so loses only 30 pixels at the panel edges, but may fail to identify the smallest and faintest spots due to over-fitting of the data. Over the available data, consistently good results were obtained using a smoothing span of 1/15, leaving a border of 68 pixels (13.6mm) at the top and bottom edges of the panel that cannot be checked; in normal operation, objects are not generally placed this close to the edges of the panel, so this is a reasonable compromise. \nb{add something on sensitivity to smoothing span after proper investigation: also on minimum discoverable defect size?}. 

%----------------------------------------------------
% screen spots - procedure in pictures
\begin{figure}
\caption{Stages of screen spot detection, illustrated on a section of the white image acquired on 14-10-09. The section contains 4 dim spots, and also crosses the midline of the panel. \\
\footnotesize{All pixel values are shaded to reflect their distance from the median value in multiples of the SD. \\ To allow clearer comparison, the residual images (c), (d) and (e) are all coloured according to the same absolute scale.}}

\newcommand{\sfwidth}{0.24\textwidth}
\newcommand{\sfscaleIV}{0.2}

\centering
\begin{subfigure}[t]{\sfwidth}
\caption{Raw image}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-raw-image}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Offset adjusted}
\label{fig:screen-spots:offset}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-offset-adj}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Lowess residuals}
\label{fig:screen-spots:lowess-res}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-loess-res}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Truncated residuals}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-loess-res-trunc}
\end{subfigure}
%

\vspace*{\baselineskip}

\begin{subfigure}[t]{\sfwidth}
\caption{Closing applied}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-closing}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Thresholded}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-thresholded}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Spots dilated}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-enlarged}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Final identification}
\label{fig:screen-spots:overlay}
\includegraphics[scale=\sfscaleIV]{screen-spots/ss-overlaid}
\end{subfigure}

\end{figure}
%----------------------------------------------------

The fitted trend is removed by subtracting each columnwise fitted curve from the column's values and, since we are looking specifically for dim patches in this case, we ignore any deviations above the fitted trend, truncating the data at the median value (\ref{fig:screen-spots:lowess-res}). To identify only those dim pixels that form large, rounded-edged clusters (as opposed to single pixels, lines or small clusters), we perform a morphological closing \cite{Vincent1997} over the resulting residual image, using a disc-shaped structuring element. Any size of structuring element may be used, with the diameter determining the minimum size of defect that will be retained; the analysis above uses a disc of diameter 5 pixels, retaining defects of 1mm or greater diameter. 

A threshold of -1 standard deviation of the untruncated Lowess residuals is used to binarise the data into spots and healthy pixels; smaller residual differences than this are generally the result of poor spline fitting, rather than of screen contamination. Finally, to approximately reconstruct the edges of each spot, which are trimmed away by the spline fitting process, we perform a morphological dilation of the spots, using the same structuring element. Figure~\ref{fig:screen-spots:overlay} shows the pixels selected by this method.

The results of this procedure can be assessed by comparing the results from two successive acquisitions (unless, of course, the screen has been replaced in the interim). \nb{assess results on consecutive acquisitions: what appears/disappears? Need to perfect spot-matching algorithm to check this!}

The approach above is easily tuned by adjusting the minimum defect diameter and smoothing span; the algorithm can be applied to any bright image (grey or white), but the clearest results were generally found to be obtained from the white images.

It should be noted that many of the pixels identified as covered by screen spots will appear normal after the shading correction is applied; generally, only pixels under the thickest part of the spot will still appear as a dark patch in the corrected image, so adding the the whole spot to the bad pixel map would remove a relatively large number of useable pixels along with the genuinely problematic. Those pixels that should be added to the bad pixel map can be identified using the criteria listed in section \nb{ref}; however, separate identification of screen spots will ensure that the affected pixels are not misclassified as independently underperforming. Identification also allows the operator to  quantify the area affected by such spots, and so to make an objective judgement of whether the beryllium window needs to be replaced. In the current data set, the highest observed affected proportion of the detector was 0.3\% (in the images acquired on 16-03-14), after which the window was replaced at the operator's request.

\subsubsection{Full-column and full-row defects}

Because of the way in which data is read out in these CCDs (first passing along each column to a sensor at the detector edge, then row-by-row to a charge amplifier \nb{?}, as shown in Figure~\ref{fig:charge-transfer-direction}), it is possible for whole columns of a subpanel to behave abnormally. The study data set contains several instances of columns of dark pixels, extending the full distance from the panel midline to the edge of the visible region. (Recall that the upper and lower panel arrays are electrically separated at the horizontal midline, so this is effectively the full length of the readout channel)

None of the images obtained in the study cover the full 2048-pixel span of the detector, so it is impossible to state categorically whether the problem originates in the channel's readout sensor, or in a specific pixel on the panel's unobserved border. However, there generally appears to be a qualitative difference between lines that have visible endpoints and those that do not. Of the 17 unique cases where a dark line terminates in the observed region of the detector, 16 show a slight upturn before normal readout resumes, with only 1 dark line showing a drop before returning to normal levels. Of the 5 unique cases where a dark line runs the full length of a subpanel, all show a slight decrease in value at the edge of the panel at all three power settings. These are very small sample sizes from which it is impossible to draw any firm conclusions, but the indications are that those dark columns that extend the full distance from the panel's midline to its edge are of a different type to those that terminate at a specific pixel. As such, our analysis will assume that these are defects in a whole readout channnel, rather than caused by a specific pixel, and will treat the pixels in these columns as unreadable.

An even less common defect - one that has been observed only twice in this study, in a single panel, and to which we have found almost no references in the literature \nb{although should have a proper search!} - occurs in the `loan' panel, where a defect affects a whole row of the detector Figure~\ref{fig:row-defect}. Given that data is only transferred from row to row after the columns have been transferred to the panel edges, we must assume that this defect lies in one of the readout sensors, and so does not form part of our investigation of pixel behaviour. Indeed, row defects have only been observed which affect a whole row of the detector, never a segment of a row, or a row of a subpanel. In this case, the defect manifests as a relatively small offset against the neighbouring rows, almost identical at all three observed power settings, so is removed by the shading correction. Unfortunately, the images containing this defect were acquired at the end of the study period, so no data is available on the progression (or otherwise) of the problem. However, an informal comparison of the row with its neighbour in an uncorrected image provided by the operator one month later shows.... \nb{(Jay to send over single frame so that we can check status)}

\addfigure{Two types of row defect observed: constant offset in row 1025, gradient in 77}

\nb{secondary row defect in r1025 of loan panel - hidden by fact that sits on panel edge. Try a secondary classification approach involving neighbour-differences? Can only go one way at a time. Maybe look at differences across neighbours \& where they coincide?}

%----------------------------------------------------
\begin{figure}
\caption{Transects along defective row 77 of the `loan' panel. The observed values of the affected row and its neighbours show the same characteristic sawtooth pattern, caused by the increasing gradient from right to left over each subpanel; the overall decreasing trend of row 77 can be seen more clearly when we consider only the offset between each pixel and its upper or lower neighbours along the row, as in (b). The offset is the same at all observed power settings (c), so will be removed by the shading correction.}
\label{fig:row-defect}

%\sfquad{row-defects/row-defect-image}{Subset of black image \\}%
\sftriple{row-defects/row-defect-transect}{Transect along row 77\\ and adjacent rows}%
\sftriple{row-defects/row-defect-diffs}{Difference between row 77\\ and adjacent rows}%
\sftriple{row-defects/row-defect-powers}{Difference between rows 77\\ and 76 at each power setting}%

\end{figure}
%----------------------------------------------------

\end{document}