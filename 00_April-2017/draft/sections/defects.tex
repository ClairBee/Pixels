\providecommand{\main}{..}					% fix bibliography path
\documentclass[\main/IO-Pixels.tex]{subfiles}
   
\graphicspath{{\main/fig/defects/}}			% fix graphics path
%======================================================================

\begin{document}


\section{Defects in the panel}

\begin{outline}

Thresholding approach used

\\
Pixel attributes:

\-\ |x| black \& grey values (\& classification by degree) - also dark / hot pixels
    
\-\ |x| black \& grey residuals after median-smoothing
    
\-\ |x| linear residuals
    
\-\ |x| Gaussian spot residuals

\\
Features observed \& how to identify them:

\-\ | | screen spots
    
\-\ | | clusters
    
\-\ | | lines
    
\-\ | | dense regions (specify density of each region: could this also indicate problem with scintillator?
    
\\
Behaviour of each pixel type / feature type in shading-corrected image

\end{outline}

%======================================================================

\subsection{Identification \& Classification of abnormal pixels}

%----------------------------------------------------------------------

\subsubsection{Thresholding}

\label{sec:thresholding}

The system-defined bad pixel map uses a number of different thresholds to identify pixels displaying abnormal behaviour (see Appendix \ref{app:bpx-defn} for details), with no classification of the defect's severity. This is entirely sensible when defining a bad pixel map; a pixel either does or does not need correction, so a binary classification is sufficient. However, for a more detailed understanding of the behaviour of defective pixels - in particular, of their development over time - a more subtle classification is required. The manufacturer's software relies heavily on identification of abnormal pixels in offset-corrected images ($W-B, G-B$), but this approach fails to distinguish between high-valued defects and low-valued defects. For example, a pixel's output may be stuck at 65535 at all power settings, while another returns a value of 5000 at all power settings; one pixel is hot, the other dark, but both have a value of 0 in the offset-corrected image. To retain this distinction, we search first for pixels with extreme uncorrected values; then for locally non-uniform pixels; for pixels with a non-linear response to changes in power setting; and for pixels that otherwise fail to respond as expected to the presence of the x-ray spot.

Given the relatively small number of images available in the present study, it is not feasible to set individual thresholds for the attributes of interest based on their `expected' behaviour, as the manufacturer is able to do. Instead, we have applied a common thresholding approach to each variable of interest. A nonparametric approach is required, since we cannot generally assume that the variable will have a symmetric distribution, much less assume any particular universal distribution: \nb{cite figures showing black med-smoothed residuals}. Furthermore, since we also expect to see a large number of very extreme values in at least some of the panels, robust measures of the spread of the data are to be preferred. In particular, the SD is strongly affected by the presence of columns of dark pixels in an image\nb{ref}, the SD is 

To accommodate the expected asymmetry, we take the mode $\hat{x}$ of the kernel density of the data as the centre of the data. Dividing the data at this value gives us two subsets, $x_{upper}$ and $x_{lower}$. For each of these subsets, the dispersion from the centre can be measured using the normalised Median Absolute Deviation from $\hat{x}$, 

\begin{equation}
    nMAD(x) = 1.4826 \cdot \text{median}(|x_i - \hat{x}|)
\end{equation}

The normalisation constant ensures that, if the data were normally distributed, the nMAD would be equal to the Standard Deviation. This gives a measure of spread that is relatively easy to interpret: where the upper or lower subset of the data has an approximately half-Normal distribution, the nMAD is the same as the standard deviation, and the usual $\sigma$ limits will be roughly correct. With this in mind, we use a limit of $6 \cdot nMAD$ either side of $\hat{x}$ as the threshold beyond which a pixel will be classified as abnormal. This threshold has performed well in the current data set, but can be easily tuned by thresholding the data at different multiples of the $nMAD$, if a more or less strict classification is required.

\textbf{A note on shading}

The colour scheme applied in pixel images follows this thresholding approach, with colour shifts representing a change in 1 or 1.5 $nMAD$ from the mode, as shown in Figure \ref{fig:scale-bar}.

\begin{figure}[!ht]
    \caption{Generic scale used in all pixel images}
    \label{fig:scale-bar}

    \centering
    \includegraphics[scale=0.4]{image-scale}
\end{figure}

%----------------------------------------------------------------------

\subsubsection{Extreme-valued pixels}

The most obvious defects in any image are generally \textbf{dark pixels}, which exhibit no change in response when the x-ray source is switched on. These are usually clearly visible in illuminated images, where they appear black or very dark, but may behave normally in the black images, or even appear slightly bright. Such pixels can easily be identified by direct thresholding of a bright image; generally the white image is to be preferred over the grey, with the greater separation between the typical white and typical black value allowing a clearer distinction between normal and dark pixels. In the acquisitions in the study data set, 99.99\% of all observed black pixels had a value of less than 9940, suggesting that this would be a sensible threshold below which a single pixel in any illuminated image should be classified as dark. In practice, a slightly higher threshold of 15000GV has been applied; this is to ensure that any columns of dark pixels, which sometimes increase in value toward the panel edge as charge accumulates during readout \nb{ref?}, are captured in their entirety, while still remaining well below the normal dynamic range of the white images.

We also directly identify \textbf{hot pixels}, which are saturated without any x-ray exposure, having a grey value of 65535 even in the black images.

To identify further \textbf{globally extreme pixels}, we apply the thresholds outlined in Section \ref{sec:thresholding} directly to the pixelwise mean black and grey images. To avoid unnecessary duplication, the white image is not also thresholded directly here; with its mode at approximately 85\% of the maximum response, the white image contains many pixels with values truncated at 65535, so provides less information about the severity of the defects identified than the grey image can. Above the 6-nMAD threshold, the data is further divided at the midpoint between the threshold and the maximum value, and again at the midpoint between the threshold and that midpoint, to distinguish between degrees of brightness (Figure \ref{fig:bright-thresholds}). Additional thresholds are not applied to pixels below the lower threshold because, after dark pixels are excluded, very few pixels are dimmer than expected.

\begin{figure}[!ht]
    \caption{Thresholding of black \& grey pixelwise mean values. Images taken on Nikon loan panel on 16-07-19.}
    \label{fig:bright-thresholds}
    
    \centering

    \begin{subfigure}[!]{0.49\textwidth}
    \caption{Black pixelwise mean values}
    \includegraphics[scale = 0.45]{th-pwm-black}
    \end{subfigure}
    %
    \begin{subfigure}[!]{0.49\textwidth}
    \caption{Grey pixelwise mean values}
    \includegraphics[scale = 0.45]{th-pwm-grey}
    \end{subfigure}
    
    \vspace{12pt}
    \includegraphics[scale = 0.5]{th-scale}

\end{figure}

%----------------------------------------------------------------------
\subsubsection{Locally non-uniform pixels}

Pixels whose values fall within the normal range of responses for the detector as a whole, but differ substantially from the values of their neighbours, are classified as \textbf{locally non-uniform pixels}. Again, to identify non-uniformity in both the background current and in the pixel response, we use the pixelwise black and grey mean images separately. For each, we obtain a median-smoothed image by convolution of the image with a filtering kernel, replacing the value of each pixel $i$ with the media of the values in a $7 \times 7$ square centred at $i$. A 7-square kernel will smooth out linear defects spanning up to 3 columns, square defects of $4 \times 4$ pixels, and circular defects of diameter 5; while larger defects are possible, none were observed \nb{check} within the study data, with the exception of the dim spots that will be identified separately. The smoothed image is subtracted from the original mean image to give residual values, which are thresholded as before, to identify locally bright or dim pixels. Further `shades' of local brightness are not measured; pixels with extremely high residuals after median-smoothing will also have extremely high values before smoothing, so this classification is redundant. \nb{comment as to why we do it, then?}

%----------------------------------------------------------------------

\subsubsection{Pixels with nonlinear response}

A pixel's response to increases in power is expected to be highly linear; \nb{in particular, the calculation used in shading correction relies on this assumption, and} pixels with a nonlinear response will not be properly smoothed by the shading correction process. To test for linearity of response, we now use all three pixelwise mean images, using a robust M-estimator to predict the values of all pixels in the mid-range image $G$. For each pixel $i$ we take as explanatory variables the pixel's values in the black and white images ($b_i$ and $b_i$ respectively), along with an indicator variable $u_i$, which is set to 1 if the pixel is above the panel's midline, and 0 if not. The resulting model for each pixel's response $y_i$ is therefore

\begin{equation}
    y_i = \alpha_1 + \alpha_2 u_i + \beta_1 b_i + \beta_2 w_i
\end{equation}

where $\alpha_1$ is a constant offset, and $\alpha_2$ is an additional offset applied only to the pixels in the upper half of the detector (where applicable), to account for any difference in gain during readout \nb{read that ACS report again - is this really what this is? Also note that gain will differ between individual subpanels, but to a lesser degree}. \nb{Include fact that manufacturer expects model to be $0.75B_i + 0.25W_i$ - can compare resulting model with this to assess whether whole panel is going awry?}. The residuals after subtracting the fitted $y_i$ from the observed $g_i$ are thresholded to identify any pixels with an unusually high or low value in the grey image, given the observed values in the black and white images.

\nb{Note about also using this image to identify spots on beryllium screen?}

\nb{Further comment: thresholding identifies only pixels with extreme values. If MAD is particularly asymmetric, or is high, then this may be indicative of problems with the linearity of the screen as a whole.}

\subsubsection{Response to conical x-ray beam}

The grey and white images are obtained by exposing the detector to an x-ray source with nothing in the field of view. X-rays diffuse out from the source in a cone until they strike the detector, resulting in an elliptical `spot' pattern, with the greatest intensity in the centre of the panel, decreasing in all directions toward the panel edge. To more clearly understand the pattern of the panel's response to this spot, we now consider only the offset-corrected values $G-B$, removing the panelwise and pixelwise differences in background current. The response $z_i$ at pixel $i$ with coordinates $(x_i, y_i)$ is well modelled by a two-dimensional Gaussian distribution \nb{cite Audrey's paper on this}, centred at the focal point $(x_0, y_0)$ of the x-ray beam, and with variances $\sigma_x$ and $\sigma_y$ reflecting the degree of dispersion of the x-rays, and $\rho$ their covariance:

\begin{equation}
   z_i = \frac{1}{2\pi \sigma_y \sigma_x \sqrt{(1-\rho^2)}} \exp \left[ -\frac{1}{2(1-\rho^2)} \left[ \left(\frac{x_i-x_0}{\sigma_x}\right)^2 + \left(\frac{y_i-y_0}{\sigma_x}\right)^2 - 2\rho\left(\frac{x_i-x_0}{\sigma_x} \right) \left(\frac{y_i-y_0}{\sigma_y} \right) \right] \right]
\end{equation}

We know that the x-ray source is directed at the centre of the panel in both axes, so we constrain $x_0$ and $y_0$ to fall within a 512-pixel-square with its centre at the midpoint of the panel. We also know that the source is more or less orthogonal to the centre of the panel, so that there is minimal stretching or distortion of the spot. We can therefore simplify the model, fixing $rho=0$, since non-zero covariance would lead to a diagonal stretching of the spot. This leaves a much simpler model, the parameters of which are easily estimated by least-squares optimisation:

\begin{equation}
z_i = A \exp \left(-\frac{1}{2} \left\lbrace \left(\frac{x_i - x_0}{\sigma_x}\right)^2 + \left(\frac{y_i - y_0}{\sigma_y}\right)^2 \right\rbrace \right) , \, \, \, \, \, \, x_0, y_0 \in (768, 1280) 
\end{equation}

The constraint on $x_0$ and $y_0$ has no effect on the fitting of the model when the spot is well-centred (Figure \ref{fig:spot-centred}). However, if the spot is off-centre (\ref{fig:spot-wonky}), or if the shape of the panel's overall response is otherwise not elliptical (\ref{fig:spot-doughnut}), then either $x_0$ or $y_0$ will lie on the constraint boundary, and further investigation is required. Visual inspection of the images will usually confirm which of these is the case, but an objective measure of the relative fits of the two models is obtained by comparing Root Mean Squared Error (RMSE) of both models. An improvement in the RMSE of the unconstrained model indicates that the spot is focussed outside of the constraint region; this does not indicate a problem with the panel itself, so the unconstrained model should be used, but does indicate that the spot should be realigned \nb{and/or...}

\nb{model selection approach WITHOUT model selection? anything better than comparison of RMSE? Need a formal test, ideally, but no way to determine appropriate thresholds.}

% Mallows' CP is for testing between subsets of explanatory variables - not the case here. Stick with RMSE until better solution found.

However, where the fit of the data is not improved to any significant degree by removing the constraint, we must conclude that an elliptical model is not appropriate for this image - wherever it is centred - and therefore that the panel as a whole is not responding as we would expect to the spot. Here, we will threshold the residual from the constrained model to identify the most extreme cases - with the caveat that, since large regions of the panel are not behaving as they should, the spread of the residuals is likely to be very wide, and so we are unlikely to identify very many individual pixels as outliers. \nb{what should we do instead? Advise operators to check the post-processed images?}


\begin{figure}[!ht]
\caption{Gaussian spot models fitted to the offset-corrected grey images, with (black) and without (red) constraints on the values of $x_0$ and $y_0$.} 
    
    \begin{subfigure}[t]{0.33\textwidth}
        \caption{16.04.30: spot well centred\\RMSE: 186}
        \label{fig:spot-centred}
        \includegraphics[scale=0.165]{spot-centred}
    \end{subfigure}
    %
    \begin{subfigure}[t]{0.33\textwidth}
        \caption{16.07.05: spot poorly centred \\RMSE: 501 constrained, 226 free}
        \label{fig:spot-wonky}
        \includegraphics[scale=0.165]{spot-off-centre}
    \end{subfigure}
    %
    \begin{subfigure}[t]{0.33\textwidth}
        \caption{\nb{new name}: non-elliptical response \\RMSE: 574 constrained, 553 free}
        \label{fig:spot-doughnut}
        \includegraphics[scale=0.165]{spot-doughnut}
    \end{subfigure}

\end{figure}

%======================================================================

\subsection{Spots on detector window}
    
A problem not related to defects in the detector panel itself, but nonetheless one that an operator must be aware of is the issue of spots appearing on the thin sheet of beryllium that isolates the x-ray source from the scintillator. These spots occur when the tungsten target is heated by the electron beam to such a degree that tiny flecks of tungsten are ejected, and attach themselves to the beryllium window. Once this occurs, the flecks remain permanently attached to the window until it is replaced. Due to the small size and thinness of the spots, they appear only very faintly, making detection difficult.

Screen spots should be removed by the manufacturer's post-processing (although not always by the shading-correction algorithm); however, the identification and correction of the small shadows of the spots is not straightforward. In particular, when taking a lengthy set of exposures, the apparent position of the spots may shift slightly as the target heats up, with the locations determined at the beginning of the scan inaccurate for images acquired at the end of the scan. This effect can be seen in \nb{add figure}; the positions of the spots vary slightly in the grey and white images taken \nb{how many?} minutes apart, with the resulting discrepancy clearly visible in an image of the residuals after a linear model is fitted. \nb{Speculative: does this happen in all images, or is it removed when the machine is warm enough? If this is the case, could it be used as an indicator for whether machine is warm enough?} While a single set of calibration images cannot assist directly in overcoming this problem, it provides an objective measure of the numbers of pixels affected by these spots, allowing the operator to assess whether the screen should be replaced. In addition to this, dim pixels that are caused by a screen spot can be excluded from the bad pixel list, since the pixels themselves are behaving normally.

\subsubsection{Identification of spots}

Screen spots are identified in both the white mean image and the residual image after a linear model has been fitted. This is in part to ensure the maximum chance of picking up all of the spots; some are more clearly identified in the white image, others in the linear residuals, depending on how well-aligned the spot positions are in the grey and white images. The same basic procedure is applied in both cases, looking for dim spots in the white image and both bright and dim spots in the linear residuals; the resulting sets of spots can be compared to evaluate the offset distance between the white and grey images. 

Our aim is to fit a smooth spline to each column of the image array; to use this spline to de-trend each column's data; and finally to identify large, round-edged dips in the detrended residuals. Detrending in both directions at once is theoretically possible, but two-dimensional spline fitting is extremely time-consuming, whereas the approach suggested here can be implemented in a matter of minutes. We use columns rather than rows to minimise the number of subpanels crossed by each spline, since the response surface is usually discontinuous at boundaries between subpanels.

Rather than fit a separate spline to the upper and lower segment of each column - which would result in a horizontal strip of unfitted pixels across the critical central region of the panel at the end of each spline - we first apply an offset correction to each column separately to smooth the join between the upper and lower panels, calculating the difference in median value of the 100 pixels above and 100 below the midline, and subtracting the difference from the values of the whole upper column (Figure \ref{fig:spot-id-offset-adj}). 

The overall trend of the pixel responses in each column is modelled by a nonparametric Lowess curve fitted to the offset-adjusted values, controlled by a smoothing parameter $\alpha$, denoting the proportion of the available data to be used in fitting each point. This parameter must be large enough that the fitted curve does not follow the short dips in value caused by the presence of contaminants, but small enough that we don't lose an unacceptable number of pixels at the ends of the spline, at the upper and lower edges of the panel. On the available data, consistently good results were obtained using a smoothing span of 1/15, leaving a border of 68px (13.6mm) at the top and bottom edges that cannot be checked; in normal operation, objects are not generally placed this close to the edges of the panel, so this is a reasonable compromise. \nb{add something on minimum discoverable spot size?}

The fitted trend is removed from each column by subtracting the fitted curve from the column's values and, since we are looking specifically for dim patches in this case, we ignore any deviations above the fitted trend, truncating the residuals at 0 (Figure \ref{fig:spot-id-truncated}). To identify only those dim pixels that form large groups with rounded edges, we perform a morphological closing \cite{Vincent1997} over the resulting image, using a disc-shaped structuring element. The size of this element will determine the minimum size of dim patch that will be retained; our analysis uses a disc of 5 pixels' diameter, retaining defects of 1mm or greater diameter (\ref{fig:spot-id-closing}).

A threshold of -1 nMAD of the untruncated Lowess residuals is used to binarise the data into spots and healthy pixels; finally, to reconstruct the edges of each spot, which tend to be slightly blurred during the spline fitting process, we perform a morphological dilation of the spots, using the same structuring element. Figure \ref{fig:s-spots} shows an example of the process applied to a pixelwise mean image; exactly the same process is repeated twice to assess the linear residual image, once to identify dim patches, and once to identify bright patches for comparison. In the latter case, the truncation is applied to all residuals below 0, an opening is used instead of a closing, and the spots are binarised using a threshold of 1 nMAD; an equivalent procedure would be to simply subtract all residuals from 0 after truncation.

\addfigure{Brief discussion of numbers of pixels found in the data? Mean spot size, area covered, distribution etc}

%----------------------------------------------------
% screen spots - procedure in pictures
\begin{figure}
\caption{Stages of screen spot detection, illustrated on a section of the white image acquired on 14-10-09. The section contains 2 dim spots, and also crosses the midline of the panel. \\
\footnotesize{To allow clearer comparison, the residual images (c), (d) and (e) are all coloured using the MAD distances of the residuals in (c).}}
\label{fig:s-spots}

\newcommand{\sfwidth}{0.24\textwidth}
\newcommand{\sfscaleIV}{0.22}

\centering
\begin{subfigure}[t]{\sfwidth}
\caption{Raw image}
\includegraphics[scale=\sfscaleIV]{s-spots-raw}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Offset adjusted}
\label{fig:spot-id-offset-adj}
\includegraphics[scale=\sfscaleIV]{s-spots-midline-adj}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Lowess residuals}
\includegraphics[scale=\sfscaleIV]{s-spots-lowess-res}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Truncated residuals}
\label{fig:spot-id-truncated}
\includegraphics[scale=\sfscaleIV]{s-spots-truncated-res}
\end{subfigure}
%

\vspace*{\baselineskip}

\begin{subfigure}[t]{\sfwidth}
\caption{Closing applied}
\label{fig:spot-id-closing}
\includegraphics[scale=\sfscaleIV]{s-spots-closing}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Thresholded}
\includegraphics[scale=\sfscaleIV]{s-spots-thresholded}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Spots dilated}
\includegraphics[scale=\sfscaleIV]{s-spots-dilated}
\end{subfigure}
%
\begin{subfigure}[t]{\sfwidth}
\caption{Final identification}
\includegraphics[scale=\sfscaleIV]{s-spots-final}
\end{subfigure}
%

\end{figure}
%----------------------------------------------------


%======================================================================

\subsection{Multi-pixel features}

\subsubsection{Dense regions}

Areas of the panel that are particularly densely populated by abnormal pixels may indicate a problem with the subpanel that goes beyond the level of defective pixels. In the study data, dense regions of pixels were observed only around the edges of the panels, usually in the corners; in at least one instance \nb{give refs}, these damaged areas were found to be symptomatic of delamination of the layers of the detector panel, resulting in a characteristic `hatched' pattern. \nb{check this with Jay. And give fig}


\subsubsection{Linear features: column defects}

Data in a CCD panel is read out by transferring charge vertically along the columns, from the midline towards charge amplifiers situated at the upper and lower edges of the panel (or, in the case of the AN1620 model used to capture one acquisition - which has only a single row of subpanels - from the top of the panel to the bottom). It is not uncommon for whole columns of a subpanel - or segments thereof - to behave abnormally; the study data set contains a number of instances of columns of abnormal defects. In the most obvious cases, a column of dark pixels will occur; dark columns always have one end at the midline (or, in the AN1620 images, the top of the panel), indicating a failure to transfer the charge from the `upstream' pixels beyond a defect. Less obviously, and less severely, columns - or segments thereof - may be either slightly brighter or slightly dimmer than their neighbours. Again, dimmer line segments always abut the panel midline, with brighter segments touching the outer edge, suggesting that in the former case, a small amount of charge is being lost from upstream pixels, and in the latter, a small charge is being added to the downstream pixels. These column defects may occur singly or, less frequently, in twos or threes, and may cover the full visible length of the channel from the midline to the panel edge, or may terminate within the active region of the detector. 

\addfigure{Charge diagram showing columns only, with `upstream' \& `downstream' directions marked}

None of the images obtained in the study cover the full 2048-pixel span of the detector, so in cases where the whole visible length of a column is affected, it is not possible to state categorically whether the problem originates in the channel's readout sensor, or in a specific pixel on the panel's unobserved border \nb{Could add brief mention of apparent difference in behaviour between partial lines? - of 17 unique columns where terminus is visible, 16 show slight upturn before normal readout resumes, with only 1 dark line showing a drop before returning to normal levels. But v small sample size}. Our analysis will therefore assume that any lines that cover the full length of a readout channel are the result of a problem with the whole readout channel, rather than being caused by a problem in the pixel at the edge of the panel.

Column defects are identified by converting the pixel map to a binary image, marked 1 where a pixel is behaving abnormally, and 0 otherwise, and convolving this binary image with a kernel designed to highlight vertical edges \nb{fig}. \nb{need to change convolution kernel to identify wider lines - currently only picking up single lines, doubles are lost/blurred, triples will lose midline altogether. Maybe set max column width \& iterate up to that?}


\subsubsection{Linear features: row defects}

Just as whole columns of the panel may become defective, it is possible - although seemingly rarer - for whole rows of pixels to display a common abnormality. Row defects were observed in only one of the panels in the study data, with two complete rows affected \nb{fig/ref}. Given that `horizontal' transfer of data occurs only after the charge has been transferred along the columns to the panel edges, we can only assume that this defect lies in one of the readout sensors, and so it does not form part of our investigation of pixel behaviour; as with the screen spots, we can only use the feature classification to exclude the affected pixels from our later analysis. In the cases observed, the defect manifests as a relatively small offset against the neighbouring rows, and is almost identical at all three observed power settings so is removed entirely by the shading correction. Unfortunately, the images containing this defect were acquired close to the end of the study period, so no data is available on the progression (or otherwise) of the problem. \nb{gradient/offset had reduced in set of images taken two months later - no indication of whether this is a trend, or an intermittent problem}

\subsubsection{Clusters}

Pixels that do not belong to dense or regular features may appear scattered singly across the detector, but frequently also appear in clusters of adjacent pixels. The arrangement of pixel types within these clusters suggests that each of these clusters would be better treated as a single multi-pixel defect, rather than as a collection of adjacent but independently-defective pixels; larger clusters contain a bright (sometimes dark) `root', with less-bright pixels around the edges. Clusters also show a slight tendency to spread horizontally rather than vertically \nb{paired t-tests of mean height \& width of clusters, split by size?}. \nb{Spatial distribution: compare with \& without cluster bodies at small radii. If independent, we would expect to see more than random pixels at close radii even after removing adjacent px}.

%======================================================================

\subsection{Defects identified in the data}

\addfigure{Table of raw counts?}

\addfigure{Table of feature counts}

Discuss association with different types of pixel \& different types of feature


\end{document}