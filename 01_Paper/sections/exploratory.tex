\providecommand{\main}{..}					% fix bibliography path
\documentclass[\main/IO-Pixels.tex]{subfiles}
   
\graphicspath{{\main/fig/exploratory/}}			% fix graphics path
%======================================================================

\begin{document}

\section{Exploratory analysis of experimental data}
%----------------------------------------------------
\begin{outline}
Means: overall and spatial distribution

SDs: overall and spatial distribution

Subpanels

Refined definition of states in the experimental data; thresholds

\\
+ Compare/assess `official' thresholds in manual: why do we need to change them? (eg. in 160430, pixels with gv 65535 in all images aren't picked up as defective because 150\% of white median value is > 65535) 

+ Other indicators of poor detector health: \\ \-\  \-\ - power in vs brightness out \\ \-\  \-\ - success of shading correction (eg. non-normality: 131122 vs 160430) \\\-\  \-\ - difference from parametric spot model (should have approx. circular response)

+ Screen spots

+ Edge cropping

+ Parametric description of panel (esp. black images)

+ Comparison of images from several detectors
\end{outline}
%----------------------------------------------------
Unless stated otherwise, image plots are shaded to highlight changes in value close to the mean, with extreme values less finely binned.

Should probably formally limit our analysis to central region of detector (possibly as defined in manual?), since extreme edges are less likely to be of interest. Therefore can use median filtering etc without losing any data, since we are cropping the edge anyway.

\addfigure{May be better to split out theoretical prep vs case studies?}

\subsection{Description of data}

Rather than summarising mean values, we generally prefer the median, which is more robust to extreme values. A single dark pixel in a white image may register 40000 DN lower than their neighbours; when healthy pixels fall within a range of only 7000 or so grey values, a handful of dark pixels can have a significant effect on local mean values, but less so on a median.

\addfigure{Images of black, grey \& white pixelwise means}
\addfigure{Images of black/grey/white pixelwise SD? Or scatterplot vs pixelwise mean?}
\addfigure{Images of quadratic trend model for black, grey \& white (grey \& white with dark image removed)}
\addfigure{Images of linear gradients across subpanels}
\addfigure{Boxplots of values in each subpanel?}

\subsection{Assessing general detector health: deviations from circular spot}

\nb{Probably shouldn't introduce this first, since not an appropriate way to classify individual bad pixels (since bad model fitting could cause high residuals). Maybe could include this after general thresholding approach, and just add regional damage into bad pixels already classified?}
% essentially: find defects using the same thresholding approach, but over different images. General problems with panel response are found as deviations from a circular spot, while pixel deviations are better identified as deviations from local (median-smoothed) image. Still need to decide best order in which to carry out these two classifications.

The grey and white images are obtained by exposing the detector to an x-ray source with nothing in the field of view. X-rays diffuse out from the source in a conical shape until they strike the detector; a hypothetical `perfect' detector, \nb{get citation - speak to Jay} then, would register a circular spot pattern in the white and grey offset images (that is, white and grey images from which the black image has been subtracted, leaving only the detector's response to the presence of x-rays), and the response $z_i$ at each pixel $(x_i, y_i)$ would be well modelled by a two-dimensional Gaussian distribution, centred at the focal point $(x_0, y_0)$ of the x-ray beam and with variances $\sigma_x$ and $\sigma_y$ reflecting the degree of dispersion of the x-rays:

\[ z_i = \frac{1}{2\pi \sigma_X \sigma_Y \sqrt{(1-\rho^2)}} \exp \left[ -\frac{1}{2(1-\rho^2)} \left[ \left(\frac{x_i-xy_0}{\sigma_X}\right)^2 + \left(\frac{y_i-y_0}{\sigma_Y}\right)^2 - 2\rho\left(\frac{x_i-x_0}{\sigma_X} \right) \left(\frac{y_i-y_0}{\sigma_Y} \right) \right] \right] \]

To simplify the model, we assume that the x-ray source is directed at the centre of the panel in both axes, and that the source is more or less orthogonal to the panel, so that there is minimal stretching or distortion of the spot. We therefore fix $\rho = 0$ - since non-zero covariance would lead to a diagonal stretching of the spot - and constrain $x_0$ and $y_0$ to fall within a square with its centre at the exact midpoint of the panel. The latter constraint may be relaxed where there is good reason to believe that the spot really is off-centre (as in Figure~\ref{fig:spot-constraints-wonky}), and is generally only required when there is a region of non-responsive pixels in the centre of the panel, leading to a response surface with a dip in the centre, as in Figure~\ref{fig:spot-constraints-doughnut}. When this occurs, an unconstrained model will very often centre the spot in the region with the highest output; however, our aim here is to model the most likely location of the spot, not simply to describe the shape of the surface, and since we know that the operator will target the spot in the centre of the panel, it is more useful to force the spot to the most appropriate area. \nb{Of course, need to check with Jay if this really is the case...}

We therefore model the expected response $z$ at each pixel $i$ as

\[ z_i = A \exp \left(-\frac{1}{2} \left\lbrace \left(\frac{x_i - x_0}{\sigma_X}\right)^2 + \left(\frac{y_i - y_0}{\sigma_Y}\right)^2 \right\rbrace \right) , x_0, y_0 \in (768, 1280) \]

\begin{figure}[!ht]
\caption{Gaussian spot models fitted with (solid line, square) and without (dashed line, triangle) constraints on the possible values of $x_0$ and $y_0$. \\
\footnotesize{In (a), the spot is centred well within the constrained area, as we might expect, and the same model is fitted with and without the constraint; typical of a healthy panel with a centred spot. However, in (b) and (c), the constrained model has its centre at one of the constraining boundaries. When this occurs, we must decide whether to allow the spot's centre to be placed outside of the constraining area. In (b), the data is unimodal, and well fitted by a model in which the spot is allowed to move outside of the usual area, which gives a significant improvement in RMSE. However, in (c), removing this constraint does not lead to any appreciable improvement in the model, so we conclude that the problem with the fit is not simply one of an off-centre spot, and keep the constraint in place.}}
\label{fig:spot-constraints}

\begin{subfigure}[t]{0.328\textwidth}
\caption{16.04.30: constraint not necessary \\RMSE: 186}
\label{fig:spot-constraints-healthy}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-160430}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{16.07.05: constraint inappropriate \\RMSE: 501 constrained, 226 free}
\label{fig:spot-constraints-wonky}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-160705}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{MCT225: constraint necessary \\RMSE: 574 constrained, 553 free}
\label{fig:spot-constraints-doughnut}
\includegraphics[scale=0.3]{Gaussian-spot-constraints-MCT225}
\end{subfigure}
%

\end{figure}

\addfigure{Consider more systematic approach to model selection. Likelihood-based methods such as AIC, BIC require a log-likelihood; how do we obtain that for a surface (rather than a sparsely-observed set of points)?}

The model is fitted by minimising the squared residuals; any deviations from the expected spot shape will indicate pixels with an abnormal response to exposure to an x-ray source. Thresholding the model's residuals identifies those pixels with the most extreme responses, and these problematic individuals can then be grouped according to their formation (clusters or lines of adjacent pixels, and dense regions of non-contiguous abnormal pixels, for example). Setting an appropriate threshold is not an exact science; a cutoff based on some scalar multiple of the RMSE of the residuals for each image would be a tempting option, in that if we could reasonably assume the residuals to be normally distributed, we would expect to be able to select a controlled proportion of the most severaly damaged pixels. However, in several panels we expect to find regions with large numbers of high residuals, which will render this assumption untenable. In addition, taking a simple mean/median RMSE across all of the images acquired in the study is not really reasonable, since we have 12 images from a single fairly `healthy' detector, 6 from a known damaged detector, and two others, so simple averaging would be assuming a misleading degree of population-representativeness. Ideally, we want a measure of the variability of the residuals of healthy pixels.

A number of the panels included in this study have very obvious column defects, which will be discussed further in Section~\ref{sec:column-defects}. These column defects comprise relatively large numbers of pixels with an offset-corrected value close to zero, and when they occur, are the most significant contributor to the non-normality of the residuals. Furthermore, they can be very easily and unequivocally identified. Excluding those panels that exhibit this clear sign of damage, we take the mean RMSE of the remaining panels (242) as an approximate measure of the typical variability of less severely-affected pixels. Using a threshold of 5 times the mean RMSE would, if the residuals were normally distributed with this standard deviation, pick up around 1000 defective pixels in a 2048-square panel: a reasonable minimum sample size with which to assess whether the residuals are clustered in a particular area, or scattered across the entire detector surface. In the data collected to date, the 12 images from the WMG post-refurbishment panel contain no dark lines; taking their mean RMSE gives a limit of 1204, beyond which a residual will be considered abnormally large.

The detector manual defines the defect-density of a region of pixels as the proportion of defects in the surrounding $51 \times 51$ square. Any pixel in which more than 10\% of the pixels in the surrounding block are found to be defective is said to lie in a high-defect-density region. We can apply this same definition to identify any regions of particularly high density in the residuals.
\nb{how are edges handled?}

\begin{figure}[!ht]
\caption{Plots of residuals with absolute value greater than 1204 from the three fitted spot models fitted above. Regions of high density are shaded red.
\\ \footnotesize{With a properly fitted spot in (b), (a) and (b) are very similar; these are images taken from the same detector, several weeks apart. There is evidence of damage along the left-hand edge of the panel, extending some way along the top border, but the extreme-valued pixels are otherwise scattered throughout the panel. In the Nikon detector labelled MCT225, on the other hand, there is a very large, dense region of abnormal pixels in the centre of the screen, and several dark lines can clearly be seen.}}

\begin{subfigure}[t]{0.328\textwidth}
\caption{16.04.30: healthy panel,\\ centred spot (2611 px)}
\includegraphics[scale=0.3]{spot-residuals-160430}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{16.07.05: non-centred spot fitted without constraint (2737 px)}
\includegraphics[scale=0.3]{spot-residuals-160705}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{MCT225: dim patch in centre of panel (49425 px)}
\includegraphics[scale=0.3]{spot-residuals-MCT225}
\end{subfigure}
%

\end{figure}

As well as the proportion of the screen affected by abnormal pixels, it may also be useful for operators to monitor the mean detector response to a given power setting (or, conversely, the power required to obtain a given mean value), and also the standard deviation of the responses. 

\FloatBarrier
\subsection{Other considerations: screen spots and edge effects}
%----------------------------------------------------
% screen spots in shading correction & shifting in successive images
\begin{figure}[!ht]
\caption{Screen spots visible in the images acquired on 14-10-09 and successive dates (spots are circled for ease of identification)}
\centering

\begin{subfigure}[t]{0.328\textwidth}
\caption{White pixelwise mean image}
\includegraphics[scale=0.3]{pwm-image-141009-white}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{White shading-corrected image}
\includegraphics[scale=0.3]{sc-image-141009-white}
\end{subfigure}
%
\begin{subfigure}[t]{0.328\textwidth}
\caption{Shift in apparent position}
\includegraphics[scale=0.3]{spots-overplotted}
\end{subfigure}
\end{figure}
%----------------------------------------------------
\addfigure{Need to decide how to handle screen spots. Do they need to be removed from shading-corrected image (as suggested by plot above) or is the shading correction still effective enough that we can afford to ignore them (as suggested by the actual approach taken)? In SC image for 141009, 99.9\% of values lie between 19624 and 20225 (range of 600px)}

Screen spots that have appeared since the previous acquisition can be easily identified by subtracting the new grey or white image from the previous acquisition. However, the `shadow' cast by the spots on the detector will shift slightly in different acquisitions due to small differences in the position or angle of the x-ray source, so spots need to be identified and corrected for at each acquisition.

\subsection{Thresholding \& definitions of bad pixels}

Need to consider \& justify the local thresholding limit. Currently using 2x SD of image as limit for median differences, but would surely make more sense to use a pixelwise standard deviation? Or even a local standard deviation (eg. standard deviation within kernel region)

\addfigure{Histograms showing thresholds of extreme-valued pixels}
\addfigure{Linear regression of white vs black \& grey images, showing thresholding by residuals}

\addfigure{Comparison of `official' classifications given in manual vs our thresholds}

\subsection{Larger features}

\subsubsection{Column defects}

\label{sec:column-defects}

\addfigure{Linear defects detected by subtracting a median-filtered image from the original, then convolution \& thresholding over the residuals. Since linear defects may be 2 or 3 pixels wide (4 pixels is possible, according to the manual, but not yet observed), the smoothing kernel should be at least 7 pixels wide (5 pixels and a 3-pixel line cannot be smoothed out, 3 pixels wide and a 2-pixel line cannot be smoothed out) \nb{Actually, with a square kernel (as in edge detection in traditional image processing), we lose detail where there are multiple adjacent columns. Could try linear kernel, or omit linear convolution step altogether?}}

Data in a CCD panel is read out by transferring charge vertically along columns, \nb{CONFIRM} from the midline towards amplifiers situated at the outer edges of the panel. It is not uncommon for a single defective pixel (or a cluster of pixels) to affect the behaviour of other pixels in the same column. In the most severe cases, a column of dark pixels will occur (\autoref{fig:dark column}), appearing as a black line in the grey and white images. The affected pixels exhibit no response to the presence of the x-ray source, with similar values in the black, grey and white images. Close inspection of transects along dark columns in the grey and white images often shows a stepped or sawtooth pattern of values, increasing at regular intervals  \nb{try to include this in the example images}. This regularity suggests that no additional charge is being added from the pixels along the dark column, that the root defect is somehow blocking its transfer along the channel to the readout sensor \nb{ideally, could relate this gradient to y-gradient along subpanel, but this is a tall ask}.

In less severe cases, a column may appear slightly brighter or dimmer than its neighbours, often by only a few hundred GV. Again, the offset from the neighbouring columns generally remains constant \nb{enumerate this: how many do remain constant, how many dip, how many appear in combination?}, suggesting that the offset may be the effect of additional charge being `leaked' or `drained' by the root defect, rather than a similar defect appearing in each pixel along the length of the column defect. Dim or dark columns have only been observed running from the root away from the amplifier, with bright columns only observed running from the root towards the amplifier \nb{CONFIRM}, with the two features often appearing in combination, on either side of a particularly bright or dark pixel (\autoref{fig:bright-dim column}).

%----------------------------------------------------
% transects along each type of column defect
\begin{figure}[!ht]
\caption{Pixel images and column transects showing known types of column defect in the dark images acquired on 13-11-22. In each transect, the defective column is shown in black, with an unaffected neighbouring column shown in blue for reference.}

	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Dark pixels}
	\label{fig:dark column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Bright pixels}
	\label{fig:bright column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Slightly dim pixels}
	\label{fig:dim column}
	\end{subfigure}
		%
	\begin{subfigure}[t]{0.24\textwidth}
	\caption{Bright and dim pixels}
	\label{fig:bright-dim column}
	\end{subfigure}
	
\end{figure}
%----------------------------------------------------	
\end{document}
